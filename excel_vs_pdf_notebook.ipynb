{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0848176c",
   "metadata": {},
   "source": [
    "# Excel â†” PDF/Image Comparator (Notebook)\n",
    "Upload two files in this runtime, extract table from PDF/Image, compare to Excel/CSV, and export CSV reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8be5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "try:\n",
    "    import pytesseract\n",
    "    TESS_AVAILABLE = True\n",
    "except Exception:\n",
    "    TESS_AVAILABLE = False\n",
    "\n",
    "def normalize_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_string_dtype(df[c]) or df[c].dtype == \"object\":\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def read_structured(path: str) -> pd.DataFrame:\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path, dtype=str, keep_default_na=False)\n",
    "    else:\n",
    "        df = pd.read_excel(path, dtype=str)\n",
    "    return normalize_df(df)\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path: str):\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            try:\n",
    "                candidates = page.extract_tables(table_settings={\n",
    "                    \"vertical_strategy\": \"lines\",\n",
    "                    \"horizontal_strategy\": \"lines\",\n",
    "                    \"intersection_tolerance\": 5\n",
    "                })\n",
    "            except Exception:\n",
    "                candidates = page.extract_tables()\n",
    "            for tbl in candidates or []:\n",
    "                if not tbl or len(tbl) < 2:\n",
    "                    continue\n",
    "                header = [str(h).strip() if h is not None else f\"col_{i}\" for i, h in enumerate(tbl[0])]\n",
    "                rows = [[(\"\" if x is None else str(x).strip()) for x in r] for r in tbl[1:]]\n",
    "                width = max(len(header), *(len(r) for r in rows)) if rows else len(header)\n",
    "                header = (header + [f\"col_{i}\" for i in range(len(header), width)])[:width]\n",
    "                rows = [ (r + [\"\"] * (width - len(r)))[:width] for r in rows ]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "                df = normalize_df(df)\n",
    "                tables.append(df)\n",
    "    return tables\n",
    "\n",
    "def extract_table_from_image(img_path: str):\n",
    "    if not TESS_AVAILABLE:\n",
    "        return []\n",
    "    img = Image.open(img_path)\n",
    "    data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DATAFRAME)\n",
    "    if \"line_num\" not in data.columns or data.empty:\n",
    "        return []\n",
    "    data = data.dropna(subset=[\"text\"])\n",
    "    data = data[data[\"text\"].str.strip() != \"\"]\n",
    "    if data.empty:\n",
    "        return []\n",
    "    group_cols = [\"page_num\", \"block_num\", \"par_num\", \"line_num\"]\n",
    "    lines = (\n",
    "        data.sort_values([\"page_num\", \"block_num\", \"par_num\", \"line_num\", \"word_num\"])\n",
    "            .groupby(group_cols)[\"text\"]\n",
    "            .apply(lambda toks: \" \".join([str(t) for t in toks]))\n",
    "            .reset_index()\n",
    "    )\n",
    "    if lines.empty:\n",
    "        return []\n",
    "    df = pd.DataFrame({\"ocr_line\": lines[\"text\"].astype(str).str.strip()})\n",
    "    df = df[df[\"ocr_line\"] != \"\"]\n",
    "    if df.empty:\n",
    "        return []\n",
    "    return [df.reset_index(drop=True)]\n",
    "\n",
    "def combine_tables(tables):\n",
    "    tables = [t for t in tables if t is not None and not t.empty]\n",
    "    if not tables:\n",
    "        return None\n",
    "    cleaned = []\n",
    "    for df in tables:\n",
    "        df = df.copy()\n",
    "        df.columns = [str(c).strip() for c in df.columns]\n",
    "        keep_cols = [c for c in df.columns if not (df[c].astype(str).str.strip() == \"\").all()]\n",
    "        if keep_cols:\n",
    "            df = df[keep_cols]\n",
    "        cleaned.append(df)\n",
    "    picked = max(cleaned, key=lambda d: d.shape[0] * max(1, d.shape[1]))\n",
    "    return normalize_df(picked)\n",
    "\n",
    "def pick_key_columns(dfA: pd.DataFrame, dfB: pd.DataFrame):\n",
    "    common = [c for c in dfA.columns if c in dfB.columns]\n",
    "    if not common:\n",
    "        return []\n",
    "    preferred = [c for c in common if c.lower() in {\"id\", \"key\", \"sku\"} or c.lower().endswith(\"_id\")]\n",
    "    if preferred:\n",
    "        return preferred\n",
    "    candidate = []\n",
    "    n = max(1, len(dfA))\n",
    "    for c in common:\n",
    "        try:\n",
    "            uniq = dfA[c].nunique(dropna=True) / n\n",
    "            if uniq > 0.8:\n",
    "                candidate.append(c)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if candidate:\n",
    "        return candidate[:3]\n",
    "    return common[:3]\n",
    "\n",
    "def compare_dataframes(dfA: pd.DataFrame, dfB: pd.DataFrame):\n",
    "    dfA = normalize_df(dfA)\n",
    "    dfB = normalize_df(dfB)\n",
    "    keys = pick_key_columns(dfA, dfB)\n",
    "    if not keys:\n",
    "        common_cols = [c for c in dfA.columns if c in dfB.columns]\n",
    "        left = dfA[common_cols].assign(_src=\"A\")\n",
    "        right = dfB[common_cols].assign(_src=\"B\")\n",
    "        merged = left.merge(right[common_cols], how=\"outer\", indicator=True)\n",
    "        missing_in_B = merged[merged[\"_merge\"] == \"left_only\"][common_cols]\n",
    "        missing_in_A = merged[merged[\"_merge\"] == \"right_only\"][common_cols]\n",
    "        value_mismatches = pd.DataFrame(columns=[\"column\", \"value_A\", \"value_B\"])\n",
    "        return missing_in_B, missing_in_A, value_mismatches, keys\n",
    "    left_only = dfA.merge(dfB[keys].drop_duplicates(), on=keys, how=\"left\", indicator=True)\n",
    "    missing_in_B = left_only[left_only[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "    right_only = dfB.merge(dfA[keys].drop_duplicates(), on=keys, how=\"left\", indicator=True)\n",
    "    missing_in_A = right_only[right_only[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "    a_idx = dfA.set_index(keys); b_idx = dfB.set_index(keys)\n",
    "    shared_index = a_idx.index.intersection(b_idx.index).drop_duplicates()\n",
    "    a_aligned = a_idx.loc[shared_index]; b_aligned = b_idx.loc[shared_index]\n",
    "    common_cols = [c for c in a_aligned.columns if c in b_aligned.columns and c not in keys]\n",
    "    mismatch_records = []\n",
    "    for idx in shared_index:\n",
    "        idx_tuple = (idx,) if not isinstance(idx, tuple) else idx\n",
    "        rowA = a_aligned.loc[idx]; rowB = b_aligned.loc[idx]\n",
    "        for col in common_cols:\n",
    "            va = \"\" if col not in rowA else (\"\" if pd.isna(rowA[col]) else str(rowA[col]))\n",
    "            vb = \"\" if col not in rowB else (\"\" if pd.isna(rowB[col]) else str(rowB[col]))\n",
    "            if va != vb:\n",
    "                rec = {\"column\": col, \"value_A\": va, \"value_B\": vb}\n",
    "                for i, k in enumerate(keys):\n",
    "                    rec[k] = idx_tuple[i]\n",
    "                mismatch_records.append(rec)\n",
    "    value_mismatches = pd.DataFrame(mismatch_records)\n",
    "    if not value_mismatches.empty:\n",
    "        value_mismatches = value_mismatches[[*keys, \"column\", \"value_A\", \"value_B\"]]\n",
    "    return missing_in_B, missing_in_A, value_mismatches, keys\n",
    "print(\"Helpers ready.\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534c957",
   "metadata": {},
   "source": [
    "## Usage\n",
    "1. Put your Excel/CSV at a path like `data.xlsx`\n",
    "2. Put your PDF or image at a path like `table.pdf` or `table.png`\n",
    "3. Run the cell below with your filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683dc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example:\n",
    "excel_path = \"data.xlsx\"   # change me\n",
    "other_path = \"table.pdf\"   # change me\n",
    "\n",
    "df_struct = read_structured(excel_path)\n",
    "if other_path.lower().endswith(\".pdf\"):\n",
    "    tables = extract_tables_from_pdf(other_path)\n",
    "else:\n",
    "    tables = extract_table_from_image(other_path)\n",
    "extracted = combine_tables(tables)\n",
    "\n",
    "missing_in_B, missing_in_A, value_mismatches, keys_used = compare_dataframes(df_struct, extracted)\n",
    "\n",
    "print(\"Detected keys:\", keys_used)\n",
    "print(\"Missing in PDF/Image:\", len(missing_in_B))\n",
    "print(\"Missing in Excel:\", len(missing_in_A))\n",
    "print(\"Value mismatches:\", len(value_mismatches))\n",
    "\n",
    "# Save reports\n",
    "if len(missing_in_B): missing_in_B.to_csv(\"missing_in_pdf_image.csv\", index=False)\n",
    "if len(missing_in_A): missing_in_A.to_csv(\"missing_in_excel.csv\", index=False)\n",
    "if len(value_mismatches): value_mismatches.to_csv(\"value_mismatches.csv\", index=False)\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
